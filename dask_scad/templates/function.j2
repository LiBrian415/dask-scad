#@ type: compute
{%- if parents %}
#@ parents:
{%- for p in parents %}
#@    - {{p.get_id()}}
{%- endfor %}
{%- endif %}
{%- if dependents %}
#@ dependents:
{%- for d in dependents %}
#@    - {{d.get_id()}}
{%- endfor %}
{%- endif %}
{%- if corunning %}
#@ corunning:
{%- for c in corunning %}
#@    {{c.get_id()}}:
#@        trans: {{c.get_id()}}
#@        type: rdma
{%- endfor %}
{%- endif %}

import base64
import cloudpickle

from dask.core import _execute_task

limit = 1000 * 1000

def main(params, action):
    key = cloudpickle.loads({{ key }})
    output = {{ '\'' + output + '\''}}
    computation = {{ computation }}

    # Input Processing
    cache = dict()
    for _, v in params.items():
        (k, t, a, s) = cloudpickle.loads(base64.b64decode(v[0]['mem']))

        trans = action.get_transport(t, 'rdma')
        trans.reg(s)

        for i in range(0, s, limit):
            ts = min(limit, s-i)
            trans.read(ts, a+i, i)

        cache[k] = cloudpickle.loads(trans.buf[:s])

    # Execute Task
    df = _execute_task(cloudpickle.loads(computation), cache)

    # Output Processing
    serialized = cloudpickle.dumps(df)
    address = 0
    size = len(serialized)

    trans = action.get_transport(output, 'rdma')
    trans.reg(size)
    trans.buf[:] = serialized

    for i in range(0, size, limit):
        ts = min(limit, size-i)
        trans.write(ts, address+i, i)

    return {'mem': base64.b64encode(cloudpickle.dumps((key, output, address, size))).decode('ascii')}

